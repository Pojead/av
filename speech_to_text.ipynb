{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech_to_text.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pojead/av/blob/main/speech_to_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speech to Text\n",
        "\n",
        "Part of your job is to produce a weekly summary (an intelligence report) of what is happening in your field. Sources of content include\n",
        "* Social Media\n",
        "* Webpages\n",
        "* YouTube\n",
        "* Podcasts\n",
        "* Blog posts\n",
        "* Reports\n",
        "* Articles\n",
        "\n",
        "I am sure you can think of many more. It would be great if we could write a program to create this report.\n",
        "\n",
        "There is a lot to do here. Gather the data, summarise the data and collate it into a document. How do we process video or a podcast? How can I get data from a webpage or a database? How can I summarise this data? Can I save the data as an excel spreadsheet or word document?\n",
        "\n",
        "A good strategy would be not to solve it all at once. Can we easily break it down into a few more straightforward problems? If we can solve and combine in the right way the simple issues, we should be able to solve the bigger problem. This approach of breaking a problem into subsystems is known as top-down design or programming. We look more closely at this approach in later modules.  \n",
        "\n",
        "Our general approach will be to take a source of content and convert that content into text. If needed, summarise the text and append it to our report. Then tidy up the information and submit it to our boss. Except for the last step, most of these steps can be done by a computer.\n",
        "\n",
        "Today, we will focus on how to convert an audio source into text. The audio source could be a podcast, a video or some other recording. We are going to convert speech to text. If you want to know more, have a look at [The Ultimate Guide to Speech Recognition With Python](https://realpython.com/python-speech-recognition/)\n",
        "\n",
        "## Tasks\n",
        "* Import into GitHub\n",
        "* Write a program to convert speech to text\n",
        "* regularly save to GitHub with a commit message"
      ],
      "metadata": {
        "id": "WTD7HkIDMXsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#perplexity AI suggested to install this module\n",
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "id": "w4bKDMdLwl2m",
        "outputId": "45e63827-c526-4de0-b854-6161f136234d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.pacdv.com/sounds/voices/maybe-next-time-huh.wav"
      ],
      "metadata": {
        "id": "jpmIwK03SKOr",
        "outputId": "639763ac-5658-4a31-b97f-bfbd39aa3156",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-28 06:33:00--  https://www.pacdv.com/sounds/voices/maybe-next-time-huh.wav\n",
            "Resolving www.pacdv.com (www.pacdv.com)... 192.163.208.117\n",
            "Connecting to www.pacdv.com (www.pacdv.com)|192.163.208.117|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 176652 (173K) [audio/x-wav]\n",
            "Saving to: ‘maybe-next-time-huh.wav.1’\n",
            "\n",
            "maybe-next-time-huh 100%[===================>] 172.51K   173KB/s    in 1.0s    \n",
            "\n",
            "2024-03-28 06:33:02 (173 KB/s) - ‘maybe-next-time-huh.wav.1’ saved [176652/176652]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "sr.__version__"
      ],
      "metadata": {
        "id": "MhsAMqPOstwy",
        "outputId": "bcdeaa96-e9b3-4a62-a103-9ae6de440670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.10.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "r = sr.Recognizer()\n",
        "\n",
        "text = None\n",
        "\n",
        "filename = '/content/maybe-next-time-huh.wav'\n",
        "with sr.AudioFile(filename) as source:\n",
        "    audio_data = r.record(source)\n",
        "    text = r.recognize_google(audio_data)\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "id": "dnTWMPULsymB",
        "outputId": "ff105f28-e908-4475-e05a-4e60f0d78160",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maybe next time\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_file = 'text_from_speech.txt'\n",
        "\n",
        "with open(output_file, \"w\") as f:\n",
        "  f.write(text)"
      ],
      "metadata": {
        "id": "f96-nSOuvb2V"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}